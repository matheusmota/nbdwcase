version: "3.7"

services:

  spark-master:
    image: bde2020/spark-master:3.2.0-hadoop3.2
    container_name: spark-master
    ports:
      - "5050:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
  spark-worker-1:
    image: bde2020/spark-worker:3.2.0-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "5051:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  spark-worker-2:
    image: bde2020/spark-worker:3.2.0-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "5052:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
  spark-history-server:
      image: bde2020/spark-history-server:3.2.0-hadoop3.2
      container_name: spark-history-server
      depends_on:
        - spark-master
      ports:
        - "18081:18081"
      volumes:
        - /tmp/spark-events-local:/tmp/spark-events


  nifi:
    image: apache/nifi:1.12.0
    ports:
      - 8787:8080 
    environment:
      - NIFI_WEB_HTTP_PORT=8080
      - NIFI_ELECTION_MAX_WAIT=10 sec
      - NIFI_ANALYTICS_QUERY_INTERVAL=-30 mins
      - NIFI_HOME=/opt/nifi/nifi-current
      - NIFI_LOG_DIR=/opt/nifi/nifi-current/logs
      - NIFI_TOOLKIT_HOME=/opt/nifi/nifi-toolkit-current
      - NIFI_PID_DIR=/opt/nifi/nifi-current/run
      - NIFI_BASE_DIR=/opt/nifi      
    # volumes:
      # - ./resources/configs/nifi/conf:/opt/nifi/nifi-current/conf
    depends_on:
      # - spark
      - minio-s3
  

  minio-s3:
    image: minio/minio:latest
    ports:
      - 9000:9000
      - 9001:9001
    volumes:
      - minio_storage:/data
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"


  create-minio-buckets:
    image: minio/mc
    depends_on:
      - minio-s3
    restart: on-failure      
    volumes:
      - ./resources/tools:/tools
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc config host add localminio http://minio-s3:9000 minioadmin minioadmin &&
      /usr/bin/mc mb --ignore-existing localminio/bronze &&
      /usr/bin/mc policy set download localminio/bronze &&
      /usr/bin/mc mb --ignore-existing localminio/silver &&
      /usr/bin/mc policy set download localminio/silver &&
      /usr/bin/mc mb --ignore-existing localminio/gold &&
      /usr/bin/mc policy set download localminio/gold &&      
      exit 0;
      "    

  platform:
    image: nbdwcase/platform:latest
    environment:
      - JUPYTER_ENABLE_LAB=yes
      - GRANT_SUDO=yes
      # - PYSPARK_SUBMIT_ARGS= --packages "org.apache.hadoop:hadoop-aws:2.7.3,com.amazonaws:aws-java-sdk:1.7.4" pyspark-shell 
      # # - PYSPARK_SUBMIT_ARGS= --packages "org.apache.hadoop:hadoop-aws:3.3.0" pyspark-shell 
      # - SPARK_OPTS=--driver-java-options=-Xms1024M --driver-java-options=-Xmx16G --driver-java-options=-Dlog4j.logLevel=info
    ports:
      - "8888:8888"
      - "8998:8998"
      - "4040:8080"
      - "4041:8081"
      # - "4040-4080:4040-4080"
    # user: root
    volumes:
      - $PWD:/home/$USER/nbdwcase
    command: >
      /bin/bash -c "      
      jupyter notebook --ip 0.0.0.0  --NotebookApp.token='' "


  # spark:
  #   image: jupyter/pyspark-notebook:spark-2
  #   environment:
  #     - JUPYTER_ENABLE_LAB=yes
  #     - GRANT_SUDO=yes
  #     - PYSPARK_SUBMIT_ARGS= --packages "org.apache.hadoop:hadoop-aws:2.7.3,com.amazonaws:aws-java-sdk:1.7.4" pyspark-shell 
  #     # - PYSPARK_SUBMIT_ARGS= --packages "org.apache.hadoop:hadoop-aws:3.3.0" pyspark-shell 
  #     - SPARK_OPTS=--driver-java-options=-Xms1024M --driver-java-options=-Xmx16G --driver-java-options=-Dlog4j.logLevel=info
  #   ports:
  #     - "8888:8888"
  #     - "8998:8998"
  #     - "4040:8080"
  #     - "4041:8081"
  #     # - "4040-4080:4040-4080"
  #   user: root
  #   volumes:
  #     - $PWD:/home/jovyan/nbdwcase
  #   command: >
  #     /bin/bash -c "
  #     echo 'spark.jars.packages=org.apache.hadoop:hadoop-aws:2.7.3,com.amazonaws:aws-java-sdk:1.7.4' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     echo 'spark.hadoop.fs.s3a.access.key=minioadmin' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     echo 'spark.hadoop.fs.s3a.secret.key=minioadmin' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     chmod +x ./nbdwcase/resources/scripts/build_minio_endpoint_spark_var.sh && ./nbdwcase/resources/scripts/build_minio_endpoint_spark_var.sh  >> /usr/local/spark/conf/spark-defaults.conf  &&
  #     echo 'spark.hadoop.fs.s3a.path.style.access=true' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     echo 'spark.hadoop.fs.s3a.connection.ssl.enabled=false' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     echo 'spark.sql.repl.eagerEval.enabled=true' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     echo 'spark.executor.memory=8g' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     echo 'spark.driver.memory=8g' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     echo 'spark.hadoop.fs.s3a.block.size=33554432' >> /usr/local/spark/conf/spark-defaults.conf &&
  #     echo 'spark.sql.warehouse.dir=/home/jovyan/metastore/' >> /usr/local/spark/conf/spark-defaults.conf &&

  #     su - jovyan &&
  #     start-notebook.sh --NotebookApp.token='' "
 
  #     #chmod +x ./nbdwcase/resources/scripts/install_hive.sh && ./nbdwcase/resources/scripts/install_hive.sh &&
  #     # echo 'Installing apache Livy ...' && 
  #     # wget https://downloads.apache.org/incubator/livy/0.7.0-incubating/apache-livy-0.7.0-incubating-bin.zip -O apache-livy-0.7.0-incubating-bin.zip &&
  #     # unzip -o apache-livy-0.7.0-incubating-bin.zip && rm apache-livy-0.7.0-incubating-bin.zip && cd apache-livy-0.7.0-incubating-bin && mkdir logs -p &&
  #     # ./bin/livy-server start && cd ~/ &&
  #     # /usr/local/spark/sbin/start-thriftserver.sh --hiveconf hive.server2.thrift.port=10015 --conf spark.sql.warehouse.dir=/home/jovyan/metastore/ &&
  #     # jupyter labextension install @jupyterlab/toc --no-build && jupyter lab build --minimize=False && 
  #     # pip3 install -e /home/jovyan/nbdwcase/src/python/datalakecase &&

  presto:
    hostname: presto
    image: starburstdata/presto:350-e.18
    container_name: presto
    ports:
      - '18080:8080'
    volumes: 
      - ./resources/configs/presto/catalog/minio.properties:/usr/lib/presto/etc/catalog/minio.properties
      - ./resources/jars/json-serde-1.3.8-jar-with-dependencies.jar:/usr/lib/presto/lib/plugin/hive-hadoop2/json-serde-1.3.8-jar-with-dependencies.jar

  # airflow:
  #   hostname: airflow
  #   image: apache/airflow 
  #   container_name: airflow
  #   ports:
  #     - 8585:8080
  #   command: webserver



  # hadoop-hive:
  #   hostname: hadoop-master
  #   image: 'prestodb/cdh5.13-hive:latest'
  #   container_name: hadoop-master
  #   volumes:
  #     - ./resources/configs/hadoop/cdh5.13-hive/conf/core-site.xml:/etc/hadoop/conf/core-site.xml
  #     - ./resources/jars/json-udf-1.3.8-jar-with-dependencies.jar:/usr/lib/hive/lib/json-udf-1.3.8-jar-with-dependencies.jar
  #     - ./resources/jars/json-serde-1.3.8-jar-with-dependencies.jar:/usr/lib/hive/lib/json-serde-1.3.8-jar-with-dependencies.jar


  metabase:
    image: metabase/metabase
    restart: always
    ports:
      - 3000:3000
    volumes:
      - ./resources/configs/metabase/metabase-data:/metabase-data
    environment:
      MB_DB_FILE: /metabase-data/metabase.db
      JAVA_TOOL_OPTIONS: -Xmx1g


  check-services:
    image: ubuntu
    container_name: check-services
    environment:
      DEBIAN_FRONTEND: noninteractive
    volumes:
      - ./resources/tools:/tools
    restart: on-failure      
    user: root
    command: >
      /bin/bash -c "
      chmod +x /tools/* && /tools/check-services.sh
      exit 0
       "
      
  # ranger-db:
  #     image: spydernaz/apache-ranger-admin-db:latest
  #     restart: always
  #     environment:
  #         - MYSQL_ROOT_PASSWORD=admin
  #     depends_on:
  #         - "atlas"

  # apache-ranger:
  #     image: spydernaz/apache-ranger-admin:experimental
  #     depends_on:
  #         - "ranger-db"
  #     ports:
  #         - 6080:6080

  # atlas:
  #     image: spydernaz/apache-atlas:experimental
  #     ports:
  #         - 21000:21000

  # kafka:
  #     image: 'confluentinc/cp-kafka:5.0.0'
  #     environment:
  #         - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
  #         - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://:9092
  #         - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
  #         - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
  #         - ALLOW_PLAINTEXT_LISTENER=yes
  #     depends_on:
  #         - zookeeper


  # Datahub Services (adapted from datahub's library: https://github.com/datahub-project/datahub/tree/master/docker)
#   datahub-zookeeper:
#     image: confluentinc/cp-zookeeper:5.4.0
#     # env_file: zookeeper/env/docker.env
#     hostname: zookeeper
#     container_name: zookeeper
#     ports:
#       - "2181:2181"
#     environment:
#       - ZOOKEEPER_CLIENT_PORT=2181
#       - ZOOKEEPER_TICK_TIME=2000
#     volumes:
#       - zkdata:/var/opt/zookeeper

#   datahub-broker:
#     image: confluentinc/cp-kafka:5.4.0
#     # env_file: broker/env/docker.env
#     hostname: broker
#     container_name: broker
#     depends_on:
#       - datahub-zookeeper
#     ports:
#       - "29092:29092"
#       - "9092:9092"
#     environment:
#       -  KAFKA_BROKER_ID=1
#       -  KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
#       -  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
#       -  KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
#       -  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
#       -  KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
#       -  KAFKA_HEAP_OPTS=-Xms256m -Xmx256m    
#     volumes:
#       - broker:/var/lib/kafka/data/

#   # This "container" is a workaround to pre-create topics
#   datahub-kafka-setup:
#     build:
#       context: resources/docker/kafka-setup
#     image: linkedin/datahub-kafka-setup:${DATAHUB_VERSION:-head}
#     # env_file: kafka-setup/env/docker.env
#     hostname: datahub-kafka-setup
#     container_name: datahub-kafka-setup
#     environment:
#       - KAFKA_ZOOKEEPER_CONNECT=datahub-zookeeper:2181
#       - KAFKA_BOOTSTRAP_SERVER=datahub-broker:29092
#     depends_on:
#       - datahub-broker
#       - datahub-schema-registry

#   datahub-schema-registry:
#     image: confluentinc/cp-schema-registry:5.4.0
#     # env_file: schema-registry/env/docker.env
#     hostname: schema-registry
#     container_name: schema-registry
#     depends_on:
#       - datahub-zookeeper
#       - datahub-broker
#     environment:
#       - SCHEMA_REGISTRY_HOST_NAME=datahub-schemaregistry
#       - SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL=datahub-zookeeper:2181  
#     ports:
#       - "8081:8081"

#   datahub-elasticsearch:
#     image: elasticsearch:7.9.3
#     # env_file: elasticsearch/env/docker.env
#     container_name: datahub-elasticsearch
#     hostname: datahub-elasticsearch
#     ports:
#       - "9200:9200"
#     environment:
#       - discovery.type=single-node
#       - xpack.security.enabled=false
#       - ES_JAVA_OPTS="-Xms256m -Xmx256m -Dlog4j2.formatMsgNoLookups=true"

#     volumes:
#       - datahub_esdata:/usr/share/elasticsearch/data
#     healthcheck:
#         test: ["CMD-SHELL", "curl -sS --fail 'http://localhost:9200/_cluster/health?wait_for_status=yellow&timeout=0s' || exit 1"]
#         start_period: 2m
#         retries: 4

#   datahub-neo4j:
#     image: neo4j:4.0.6
#     # env_file: neo4j/env/docker.env
#     hostname: datahub-neo4j
#     container_name: datahub-neo4j
#     ports:
#       - "7474:7474"
#       - "7687:7687"
#     environment:
#     - NEO4J_AUTH=neo4j/datahub
#     - NEO4J_dbms_default__database=graph.db
#     - NEO4J_dbms_allow__upgrade=true
#     volumes:
#       - datahub_neo4jdata:/data

#   # This "container" is a workaround to pre-create search indices
#   datahub-elasticsearch-setup:
#     build:
#       context: resources/docker/elasticsearch-setup
#     image: linkedin/datahub-elasticsearch-setup:${DATAHUB_VERSION:-head}
#     # env_file: elasticsearch-setup/env/docker.env
#     hostname: datahub-elasticsearch-setup
#     container_name: datahub-elasticsearch-setup
#     environment:
#       - ELASTICSEARCH_HOST=elasticsearch
#       - ELASTICSEARCH_PORT=9200
#       - ELASTICSEARCH_PROTOCOL=http

# # Uncomment to disable persistence of client-side analytics events
# # DATAHUB_ANALYTICS_ENABLED=false
#     depends_on:
#       - datahub-elasticsearch

#   datahub-gms:
#     build:
#         context: ../
#         dockerfile: docker/datahub-gms/Dockerfile
#     image: linkedin/datahub-gms:${DATAHUB_VERSION:-head}
#     hostname: datahub-gms
#     container_name: datahub-gms
#     ports:
#       - "8080:8080"
#     depends_on:
#       - datahub-elasticsearch-setup
#       - datahub-kafka-setup
#       - datahub-mysql
#       - datahub-neo4j

#   datahub-frontend-react:
#     build:
#       context: ../
#       dockerfile: docker/datahub-frontend/Dockerfile
#     image: linkedin/datahub-frontend-react:${DATAHUB_VERSION:-head}
#     env_file: datahub-frontend/env/docker.env
#     hostname: datahub-frontend-react
#     container_name: datahub-frontend-react
#     ports:
#       - "9002:9002"
#     depends_on:
#       - datahub-gms
#     volumes:
#       - ${HOME}/.datahub/plugins:/etc/datahub/plugins

#   datahub-actions:
#     image: public.ecr.aws/datahub/acryl-datahub-actions:${ACTIONS_VERSION:-head}
#     hostname: actions
#     env_file: datahub-actions/env/docker.env
#     restart: on-failure:5
#     depends_on:
#       - datahub-gms

volumes:
  nifi_flow:
  minio_storage:
  metabase_postgres_data:
  # datahub_esdata:
  # datahub_neo4jdata:
  # datahub_zkdata:
  # datahub_broker: